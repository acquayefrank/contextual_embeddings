{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "PACKAGE_PARENT = '..'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MODELS_PATH\n",
    "from data import DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "def _load_word_embedding_model(file=f'../models/fasttext/crawl-300d-2M-subword.vec', word_embedding_type=\"fasttext\"):\n",
    "    model = {}\n",
    "    if file is None:\n",
    "        file, *ign = embeddings.get(\"GLOVE_6B_300D\")\n",
    "    print(\"Loading Model\")\n",
    "    if word_embedding_type == \"glove\":\n",
    "        df = pd.read_csv(file, sep=\" \", quoting=3, header=None, index_col=0)\n",
    "        model = {key: val.values for key, val in df.T.items()}\n",
    "        print(len(model), \" words loaded!\")\n",
    "    elif word_embedding_type == \"word2vec\":\n",
    "        model = KeyedVectors.load_word2vec_format(file, binary=True)\n",
    "    elif word_embedding_type == \"fasttext\":\n",
    "        model = KeyedVectors.load_word2vec_format(file, binary=False)\n",
    "    return model\n",
    "MODEL = _load_word_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_nn_model = f\"{MODELS_PATH}/4m-oYYqjRvqVvyu2ryjmSw_trained_models/give_FASTTEXT_CRAWL_SUB_SingleLayeredNN.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_lr_model = f\"{MODELS_PATH}/4m-oYYqjRvqVvyu2ryjmSw_trained_models/give_FASTTEXT_CRAWL_SUB_LogisticRegression.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import LogisticRegression, SingleLayeredNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleLayeredNN(\n",
       "  (fc1): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (sigmoid1): Sigmoid()\n",
       "  (fc2): Linear(in_features=300, out_features=1, bias=True)\n",
       "  (sigmoid2): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model = SingleLayeredNN(300, 300, 1)\n",
    "nn_model.load_state_dict(torch.load(fasttext_nn_model))\n",
    "nn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=300, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression(300, 1)\n",
    "lr_model.load_state_dict(torch.load(fasttext_lr_model))\n",
    "lr_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(f'{DATA_ROOT}/4m-oYYqjRvqVvyu2ryjmSw_common_words_100_final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_word_embeddings(word):\n",
    "    try:\n",
    "        return MODEL[word]\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embedding'] = df[\"actual_words\"].apply(_get_word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df.loc[:, df.columns == 'Embedding']\n",
    "y_data = df.loc[:, df.columns == 'give']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# determine the supported device\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "# convert a df to tensor to be used in pytorch\n",
    "def df_to_tensor(s_df):\n",
    "    device = get_device()\n",
    "    return Variable(torch.Tensor(s_df.values)).to(device)\n",
    "\n",
    "def complex_df_to_tensor(_df):\n",
    "    device = get_device()\n",
    "    temp_x = []\n",
    "    for index, row in _df.iterrows():\n",
    "        temp_row = []\n",
    "        row = row.to_dict()\n",
    "        g_em = []\n",
    "        for key in row.keys():\n",
    "            if key != 'Embedding':\n",
    "                temp_row.append(row[key])\n",
    "            else:\n",
    "                g_em = Variable(torch.Tensor(row[key])).to(device)\n",
    "        temp_x.append(torch.cat([\n",
    "            Variable(torch.Tensor(temp_row)).to(device), \n",
    "            g_em]\n",
    "            ,dim=0))\n",
    "\n",
    "    return torch.stack(temp_x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = df_to_tensor(y_data)\n",
    "x_data = complex_df_to_tensor(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleLayeredNN(\n",
       "  (fc1): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (sigmoid1): Sigmoid()\n",
       "  (fc2): Linear(in_features=300, out_features=1, bias=True)\n",
       "  (sigmoid2): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "lr_model.to(device)\n",
    "nn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import evaluate\n",
    "\n",
    "\n",
    "scores = evaluate(lr_model, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray:  0.9798568778160615 LogisticRegression(\n",
      "  (linear): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n",
      "AUC:  0.9741754235689413 LogisticRegression(\n",
      "  (linear): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate(lr_model, x_data, y_data)\n",
    "print(\"Accuray: \", str(scores[\"_accuracy\"]), lr_model)\n",
    "print(\"AUC: \", str(scores[\"_auc\"]), lr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray:  0.9954943016167506 SingleLayeredNN(\n",
      "  (fc1): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (sigmoid1): Sigmoid()\n",
      "  (fc2): Linear(in_features=300, out_features=1, bias=True)\n",
      "  (sigmoid2): Sigmoid()\n",
      ")\n",
      "AUC:  0.9993244311200168 SingleLayeredNN(\n",
      "  (fc1): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (sigmoid1): Sigmoid()\n",
      "  (fc2): Linear(in_features=300, out_features=1, bias=True)\n",
      "  (sigmoid2): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate(nn_model, x_data, y_data)\n",
    "print(\"Accuray: \", str(scores[\"_accuracy\"]), nn_model)\n",
    "print(\"AUC: \", str(scores[\"_auc\"]), nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}