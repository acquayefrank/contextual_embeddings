
Add data preperation and methodology 


https://arxiv.org/pdf/1808.09663.pdf


Test on all embeddings with learning rate and optimizer decay rate

More data for training and testing

Analyze weights of logistic regression
Weights 

Sentiment of words  included in word embeddings 
    Cultural Biases in word embeddings  ---------------------------------

******** Clustering of Word Embeddings

* on re-run continue


Black --- Code Linter
isort --- Sort Code
flak8 --- fix code
vulture --- unused code
coverage --- run tests
 
TODO:
    * Use common words from embeddins and repeat everything
    * Intersection of words in word embeddings, delete words  that don't have enough hypernymns 
    * Logistic Regresion --- saved 
        For each word embedding heatmap of all words in logistic regression
    * resart training on failure


-------------------------------------------------------------------------------------
How many common words are missing per word embedding
How many common words are in intersection of word embeddings
Generate reports
Generate dendograms and heatmaps 
Merge other code
-------------------------------------------------------------------------------------

Use Intersection not union ---
    Done minimum number of words = 2_702_150
    Words found in intersection = 137_245
    Words processed 136884 in 228.0505609512329 seconds
    Saved Words = 83081
Reorder rows to be dendogrum or heirachical cluster
Change numbers to names of words


Save all common words 